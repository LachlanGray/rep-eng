{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lachlangray/dev/rep-eng/repe/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model_utils import load_model_and_tokenizer, get_submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded microsoft/phi-2\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\"\n",
    "\n",
    "model_name = \"microsoft/phi-2\"\n",
    "model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def completion(text):\n",
    "    device = model.device\n",
    "    input_tokens = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=False\n",
    "    )\n",
    "    input_tokens = {k: v.to(device) for k, v in input_tokens.items()}\n",
    "\n",
    "    with torch.no_grad():  # Optional: Disables gradient calculations, useful for inference\n",
    "        output_tokens = model.generate(\n",
    "            **input_tokens,\n",
    "            do_sample=False,\n",
    "            max_length=100,\n",
    "            temperature=0.5\n",
    "        )\n",
    "    \n",
    "    # Decode the output tokens into text\n",
    "    generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=False)\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lachlangray/dev/rep-eng/repe/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who am I? What am!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who am I?\"\n",
    "text = completion(prompt)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.q_proj.bias\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.k_proj.bias\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.v_proj.bias\n",
      "model.layers.0.self_attn.dense.weight\n",
      "model.layers.0.self_attn.dense.bias\n",
      "model.layers.0.mlp.fc1.weight\n",
      "model.layers.0.mlp.fc1.bias\n",
      "model.layers.0.mlp.fc2.weight\n",
      "model.layers.0.mlp.fc2.bias\n",
      "model.layers.0.input_layernorm.weight\n",
      "model.layers.0.input_layernorm.bias\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.q_proj.bias\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.k_proj.bias\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.v_proj.bias\n",
      "model.layers.1.self_attn.dense.weight\n",
      "model.layers.1.self_attn.dense.bias\n",
      "model.layers.1.mlp.fc1.weight\n",
      "model.layers.1.mlp.fc1.bias\n",
      "model.layers.1.mlp.fc2.weight\n",
      "model.layers.1.mlp.fc2.bias\n",
      "model.layers.1.input_layernorm.weight\n",
      "model.layers.1.input_layernorm.bias\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.q_proj.bias\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.k_proj.bias\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.v_proj.bias\n",
      "model.layers.2.self_attn.dense.weight\n",
      "model.layers.2.self_attn.dense.bias\n",
      "model.layers.2.mlp.fc1.weight\n",
      "model.layers.2.mlp.fc1.bias\n",
      "model.layers.2.mlp.fc2.weight\n",
      "model.layers.2.mlp.fc2.bias\n",
      "model.layers.2.input_layernorm.weight\n",
      "model.layers.2.input_layernorm.bias\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.q_proj.bias\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.k_proj.bias\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.v_proj.bias\n",
      "model.layers.3.self_attn.dense.weight\n",
      "model.layers.3.self_attn.dense.bias\n",
      "model.layers.3.mlp.fc1.weight\n",
      "model.layers.3.mlp.fc1.bias\n",
      "model.layers.3.mlp.fc2.weight\n",
      "model.layers.3.mlp.fc2.bias\n",
      "model.layers.3.input_layernorm.weight\n",
      "model.layers.3.input_layernorm.bias\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.q_proj.bias\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.k_proj.bias\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.v_proj.bias\n",
      "model.layers.4.self_attn.dense.weight\n",
      "model.layers.4.self_attn.dense.bias\n",
      "model.layers.4.mlp.fc1.weight\n",
      "model.layers.4.mlp.fc1.bias\n",
      "model.layers.4.mlp.fc2.weight\n",
      "model.layers.4.mlp.fc2.bias\n",
      "model.layers.4.input_layernorm.weight\n",
      "model.layers.4.input_layernorm.bias\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.q_proj.bias\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.k_proj.bias\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.v_proj.bias\n",
      "model.layers.5.self_attn.dense.weight\n",
      "model.layers.5.self_attn.dense.bias\n",
      "model.layers.5.mlp.fc1.weight\n",
      "model.layers.5.mlp.fc1.bias\n",
      "model.layers.5.mlp.fc2.weight\n",
      "model.layers.5.mlp.fc2.bias\n",
      "model.layers.5.input_layernorm.weight\n",
      "model.layers.5.input_layernorm.bias\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.q_proj.bias\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.k_proj.bias\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.v_proj.bias\n",
      "model.layers.6.self_attn.dense.weight\n",
      "model.layers.6.self_attn.dense.bias\n",
      "model.layers.6.mlp.fc1.weight\n",
      "model.layers.6.mlp.fc1.bias\n",
      "model.layers.6.mlp.fc2.weight\n",
      "model.layers.6.mlp.fc2.bias\n",
      "model.layers.6.input_layernorm.weight\n",
      "model.layers.6.input_layernorm.bias\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.q_proj.bias\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.k_proj.bias\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.v_proj.bias\n",
      "model.layers.7.self_attn.dense.weight\n",
      "model.layers.7.self_attn.dense.bias\n",
      "model.layers.7.mlp.fc1.weight\n",
      "model.layers.7.mlp.fc1.bias\n",
      "model.layers.7.mlp.fc2.weight\n",
      "model.layers.7.mlp.fc2.bias\n",
      "model.layers.7.input_layernorm.weight\n",
      "model.layers.7.input_layernorm.bias\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.q_proj.bias\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.k_proj.bias\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.v_proj.bias\n",
      "model.layers.8.self_attn.dense.weight\n",
      "model.layers.8.self_attn.dense.bias\n",
      "model.layers.8.mlp.fc1.weight\n",
      "model.layers.8.mlp.fc1.bias\n",
      "model.layers.8.mlp.fc2.weight\n",
      "model.layers.8.mlp.fc2.bias\n",
      "model.layers.8.input_layernorm.weight\n",
      "model.layers.8.input_layernorm.bias\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.q_proj.bias\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.k_proj.bias\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.v_proj.bias\n",
      "model.layers.9.self_attn.dense.weight\n",
      "model.layers.9.self_attn.dense.bias\n",
      "model.layers.9.mlp.fc1.weight\n",
      "model.layers.9.mlp.fc1.bias\n",
      "model.layers.9.mlp.fc2.weight\n",
      "model.layers.9.mlp.fc2.bias\n",
      "model.layers.9.input_layernorm.weight\n",
      "model.layers.9.input_layernorm.bias\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.q_proj.bias\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.k_proj.bias\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.v_proj.bias\n",
      "model.layers.10.self_attn.dense.weight\n",
      "model.layers.10.self_attn.dense.bias\n",
      "model.layers.10.mlp.fc1.weight\n",
      "model.layers.10.mlp.fc1.bias\n",
      "model.layers.10.mlp.fc2.weight\n",
      "model.layers.10.mlp.fc2.bias\n",
      "model.layers.10.input_layernorm.weight\n",
      "model.layers.10.input_layernorm.bias\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.q_proj.bias\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.k_proj.bias\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.v_proj.bias\n",
      "model.layers.11.self_attn.dense.weight\n",
      "model.layers.11.self_attn.dense.bias\n",
      "model.layers.11.mlp.fc1.weight\n",
      "model.layers.11.mlp.fc1.bias\n",
      "model.layers.11.mlp.fc2.weight\n",
      "model.layers.11.mlp.fc2.bias\n",
      "model.layers.11.input_layernorm.weight\n",
      "model.layers.11.input_layernorm.bias\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.q_proj.bias\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.k_proj.bias\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.v_proj.bias\n",
      "model.layers.12.self_attn.dense.weight\n",
      "model.layers.12.self_attn.dense.bias\n",
      "model.layers.12.mlp.fc1.weight\n",
      "model.layers.12.mlp.fc1.bias\n",
      "model.layers.12.mlp.fc2.weight\n",
      "model.layers.12.mlp.fc2.bias\n",
      "model.layers.12.input_layernorm.weight\n",
      "model.layers.12.input_layernorm.bias\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.q_proj.bias\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.k_proj.bias\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.v_proj.bias\n",
      "model.layers.13.self_attn.dense.weight\n",
      "model.layers.13.self_attn.dense.bias\n",
      "model.layers.13.mlp.fc1.weight\n",
      "model.layers.13.mlp.fc1.bias\n",
      "model.layers.13.mlp.fc2.weight\n",
      "model.layers.13.mlp.fc2.bias\n",
      "model.layers.13.input_layernorm.weight\n",
      "model.layers.13.input_layernorm.bias\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.q_proj.bias\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.k_proj.bias\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.v_proj.bias\n",
      "model.layers.14.self_attn.dense.weight\n",
      "model.layers.14.self_attn.dense.bias\n",
      "model.layers.14.mlp.fc1.weight\n",
      "model.layers.14.mlp.fc1.bias\n",
      "model.layers.14.mlp.fc2.weight\n",
      "model.layers.14.mlp.fc2.bias\n",
      "model.layers.14.input_layernorm.weight\n",
      "model.layers.14.input_layernorm.bias\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.q_proj.bias\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.k_proj.bias\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.v_proj.bias\n",
      "model.layers.15.self_attn.dense.weight\n",
      "model.layers.15.self_attn.dense.bias\n",
      "model.layers.15.mlp.fc1.weight\n",
      "model.layers.15.mlp.fc1.bias\n",
      "model.layers.15.mlp.fc2.weight\n",
      "model.layers.15.mlp.fc2.bias\n",
      "model.layers.15.input_layernorm.weight\n",
      "model.layers.15.input_layernorm.bias\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.q_proj.bias\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.k_proj.bias\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.v_proj.bias\n",
      "model.layers.16.self_attn.dense.weight\n",
      "model.layers.16.self_attn.dense.bias\n",
      "model.layers.16.mlp.fc1.weight\n",
      "model.layers.16.mlp.fc1.bias\n",
      "model.layers.16.mlp.fc2.weight\n",
      "model.layers.16.mlp.fc2.bias\n",
      "model.layers.16.input_layernorm.weight\n",
      "model.layers.16.input_layernorm.bias\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.q_proj.bias\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.k_proj.bias\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.v_proj.bias\n",
      "model.layers.17.self_attn.dense.weight\n",
      "model.layers.17.self_attn.dense.bias\n",
      "model.layers.17.mlp.fc1.weight\n",
      "model.layers.17.mlp.fc1.bias\n",
      "model.layers.17.mlp.fc2.weight\n",
      "model.layers.17.mlp.fc2.bias\n",
      "model.layers.17.input_layernorm.weight\n",
      "model.layers.17.input_layernorm.bias\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.q_proj.bias\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.k_proj.bias\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.v_proj.bias\n",
      "model.layers.18.self_attn.dense.weight\n",
      "model.layers.18.self_attn.dense.bias\n",
      "model.layers.18.mlp.fc1.weight\n",
      "model.layers.18.mlp.fc1.bias\n",
      "model.layers.18.mlp.fc2.weight\n",
      "model.layers.18.mlp.fc2.bias\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.input_layernorm.bias\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.q_proj.bias\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.k_proj.bias\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.v_proj.bias\n",
      "model.layers.19.self_attn.dense.weight\n",
      "model.layers.19.self_attn.dense.bias\n",
      "model.layers.19.mlp.fc1.weight\n",
      "model.layers.19.mlp.fc1.bias\n",
      "model.layers.19.mlp.fc2.weight\n",
      "model.layers.19.mlp.fc2.bias\n",
      "model.layers.19.input_layernorm.weight\n",
      "model.layers.19.input_layernorm.bias\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.q_proj.bias\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.k_proj.bias\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.v_proj.bias\n",
      "model.layers.20.self_attn.dense.weight\n",
      "model.layers.20.self_attn.dense.bias\n",
      "model.layers.20.mlp.fc1.weight\n",
      "model.layers.20.mlp.fc1.bias\n",
      "model.layers.20.mlp.fc2.weight\n",
      "model.layers.20.mlp.fc2.bias\n",
      "model.layers.20.input_layernorm.weight\n",
      "model.layers.20.input_layernorm.bias\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.q_proj.bias\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.k_proj.bias\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.v_proj.bias\n",
      "model.layers.21.self_attn.dense.weight\n",
      "model.layers.21.self_attn.dense.bias\n",
      "model.layers.21.mlp.fc1.weight\n",
      "model.layers.21.mlp.fc1.bias\n",
      "model.layers.21.mlp.fc2.weight\n",
      "model.layers.21.mlp.fc2.bias\n",
      "model.layers.21.input_layernorm.weight\n",
      "model.layers.21.input_layernorm.bias\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.q_proj.bias\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.k_proj.bias\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.v_proj.bias\n",
      "model.layers.22.self_attn.dense.weight\n",
      "model.layers.22.self_attn.dense.bias\n",
      "model.layers.22.mlp.fc1.weight\n",
      "model.layers.22.mlp.fc1.bias\n",
      "model.layers.22.mlp.fc2.weight\n",
      "model.layers.22.mlp.fc2.bias\n",
      "model.layers.22.input_layernorm.weight\n",
      "model.layers.22.input_layernorm.bias\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.q_proj.bias\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.k_proj.bias\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.v_proj.bias\n",
      "model.layers.23.self_attn.dense.weight\n",
      "model.layers.23.self_attn.dense.bias\n",
      "model.layers.23.mlp.fc1.weight\n",
      "model.layers.23.mlp.fc1.bias\n",
      "model.layers.23.mlp.fc2.weight\n",
      "model.layers.23.mlp.fc2.bias\n",
      "model.layers.23.input_layernorm.weight\n",
      "model.layers.23.input_layernorm.bias\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.q_proj.bias\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.k_proj.bias\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.v_proj.bias\n",
      "model.layers.24.self_attn.dense.weight\n",
      "model.layers.24.self_attn.dense.bias\n",
      "model.layers.24.mlp.fc1.weight\n",
      "model.layers.24.mlp.fc1.bias\n",
      "model.layers.24.mlp.fc2.weight\n",
      "model.layers.24.mlp.fc2.bias\n",
      "model.layers.24.input_layernorm.weight\n",
      "model.layers.24.input_layernorm.bias\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.q_proj.bias\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.k_proj.bias\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.v_proj.bias\n",
      "model.layers.25.self_attn.dense.weight\n",
      "model.layers.25.self_attn.dense.bias\n",
      "model.layers.25.mlp.fc1.weight\n",
      "model.layers.25.mlp.fc1.bias\n",
      "model.layers.25.mlp.fc2.weight\n",
      "model.layers.25.mlp.fc2.bias\n",
      "model.layers.25.input_layernorm.weight\n",
      "model.layers.25.input_layernorm.bias\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.q_proj.bias\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.k_proj.bias\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.v_proj.bias\n",
      "model.layers.26.self_attn.dense.weight\n",
      "model.layers.26.self_attn.dense.bias\n",
      "model.layers.26.mlp.fc1.weight\n",
      "model.layers.26.mlp.fc1.bias\n",
      "model.layers.26.mlp.fc2.weight\n",
      "model.layers.26.mlp.fc2.bias\n",
      "model.layers.26.input_layernorm.weight\n",
      "model.layers.26.input_layernorm.bias\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.q_proj.bias\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.k_proj.bias\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.v_proj.bias\n",
      "model.layers.27.self_attn.dense.weight\n",
      "model.layers.27.self_attn.dense.bias\n",
      "model.layers.27.mlp.fc1.weight\n",
      "model.layers.27.mlp.fc1.bias\n",
      "model.layers.27.mlp.fc2.weight\n",
      "model.layers.27.mlp.fc2.bias\n",
      "model.layers.27.input_layernorm.weight\n",
      "model.layers.27.input_layernorm.bias\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.q_proj.bias\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.k_proj.bias\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.v_proj.bias\n",
      "model.layers.28.self_attn.dense.weight\n",
      "model.layers.28.self_attn.dense.bias\n",
      "model.layers.28.mlp.fc1.weight\n",
      "model.layers.28.mlp.fc1.bias\n",
      "model.layers.28.mlp.fc2.weight\n",
      "model.layers.28.mlp.fc2.bias\n",
      "model.layers.28.input_layernorm.weight\n",
      "model.layers.28.input_layernorm.bias\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.q_proj.bias\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.k_proj.bias\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.v_proj.bias\n",
      "model.layers.29.self_attn.dense.weight\n",
      "model.layers.29.self_attn.dense.bias\n",
      "model.layers.29.mlp.fc1.weight\n",
      "model.layers.29.mlp.fc1.bias\n",
      "model.layers.29.mlp.fc2.weight\n",
      "model.layers.29.mlp.fc2.bias\n",
      "model.layers.29.input_layernorm.weight\n",
      "model.layers.29.input_layernorm.bias\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.q_proj.bias\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.k_proj.bias\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.v_proj.bias\n",
      "model.layers.30.self_attn.dense.weight\n",
      "model.layers.30.self_attn.dense.bias\n",
      "model.layers.30.mlp.fc1.weight\n",
      "model.layers.30.mlp.fc1.bias\n",
      "model.layers.30.mlp.fc2.weight\n",
      "model.layers.30.mlp.fc2.bias\n",
      "model.layers.30.input_layernorm.weight\n",
      "model.layers.30.input_layernorm.bias\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.q_proj.bias\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.k_proj.bias\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.v_proj.bias\n",
      "model.layers.31.self_attn.dense.weight\n",
      "model.layers.31.self_attn.dense.bias\n",
      "model.layers.31.mlp.fc1.weight\n",
      "model.layers.31.mlp.fc1.bias\n",
      "model.layers.31.mlp.fc2.weight\n",
      "model.layers.31.mlp.fc2.bias\n",
      "model.layers.31.input_layernorm.weight\n",
      "model.layers.31.input_layernorm.bias\n",
      "model.final_layernorm.weight\n",
      "model.final_layernorm.bias\n",
      "lm_head.weight\n",
      "lm_head.bias\n"
     ]
    }
   ],
   "source": [
    "modules = list(model.state_dict().keys())\n",
    "print(\"\\n\".join(modules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhiSdpaAttention(\n",
      "  (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "  (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "  (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "  (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "  (rotary_emb): PhiRotaryEmbedding()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(get_submodule(model, \"model.layers.1.self_attn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern = \"model.layers.*.self_attn.v_proj\"\n",
    "\n",
    "target_modules = {}\n",
    "for module in modules:\n",
    "    match = re.search(target_pattern, module)\n",
    "    if match:\n",
    "        target_module = match.group()\n",
    "        target_modules[target_module] = get_submodule(model, target_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.layers.0.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.1.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.2.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.3.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.4.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.5.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.6.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.7.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.8.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.9.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.10.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.11.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.12.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.13.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.14.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.15.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.16.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.17.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.18.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.19.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.20.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.21.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.22.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.23.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.24.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.25.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.26.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.27.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.28.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.29.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.30.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True),\n",
       " 'model.layers.31.self_attn.v_proj': Linear(in_features=2560, out_features=2560, bias=True)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_outputs = {k: [] for k in target_modules.keys()}\n",
    "\n",
    "def record_output(module, input, output, name):\n",
    "    for i in range(output.shape[0]):\n",
    "        recorded_outputs[name].append(output[i])\n",
    "\n",
    "for name, module in target_modules.items():\n",
    "    module.register_forward_hook(partial(record_output, name=name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_samples = [\n",
    "    \"Get to the chopper\",\n",
    "    \"Do you know the muffin man\",\n",
    "    \"Hasta la vista baby\",\n",
    "    \"Sugar spice and everything nice\",\n",
    "    \"I am the terminator\",\n",
    "    \"Happy rainbow puppies\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "\n",
    "model.to(device).eval()\n",
    "\n",
    "for sample in input_samples:\n",
    "    input_tokens = tokenizer(\n",
    "        sample,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=False\n",
    "    )\n",
    "    input_tokens = {k: v.to(device) for k, v in input_tokens.items()}\n",
    "\n",
    "    outputs = model(**input_tokens, output_hidden_states=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.self_attn.v_proj: 6\n",
      "model.layers.1.self_attn.v_proj: 6\n",
      "model.layers.2.self_attn.v_proj: 6\n",
      "model.layers.3.self_attn.v_proj: 6\n",
      "model.layers.4.self_attn.v_proj: 6\n",
      "model.layers.5.self_attn.v_proj: 6\n",
      "model.layers.6.self_attn.v_proj: 6\n",
      "model.layers.7.self_attn.v_proj: 6\n",
      "model.layers.8.self_attn.v_proj: 6\n",
      "model.layers.9.self_attn.v_proj: 6\n",
      "model.layers.10.self_attn.v_proj: 6\n",
      "model.layers.11.self_attn.v_proj: 6\n",
      "model.layers.12.self_attn.v_proj: 6\n",
      "model.layers.13.self_attn.v_proj: 6\n",
      "model.layers.14.self_attn.v_proj: 6\n",
      "model.layers.15.self_attn.v_proj: 6\n",
      "model.layers.16.self_attn.v_proj: 6\n",
      "model.layers.17.self_attn.v_proj: 6\n",
      "model.layers.18.self_attn.v_proj: 6\n",
      "model.layers.19.self_attn.v_proj: 6\n",
      "model.layers.20.self_attn.v_proj: 6\n",
      "model.layers.21.self_attn.v_proj: 6\n",
      "model.layers.22.self_attn.v_proj: 6\n",
      "model.layers.23.self_attn.v_proj: 6\n",
      "model.layers.24.self_attn.v_proj: 6\n",
      "model.layers.25.self_attn.v_proj: 6\n",
      "model.layers.26.self_attn.v_proj: 6\n",
      "model.layers.27.self_attn.v_proj: 6\n",
      "model.layers.28.self_attn.v_proj: 6\n",
      "model.layers.29.self_attn.v_proj: 6\n",
      "model.layers.30.self_attn.v_proj: 6\n",
      "model.layers.31.self_attn.v_proj: 6\n"
     ]
    }
   ],
   "source": [
    "for name, outs in recorded_outputs.items():\n",
    "    print(f\"{name}: {len(outs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2560])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorded_outputs[\"model.layers.13.self_attn.v_proj\"][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_tokens = {m: [] for m in target_modules}\n",
    "\n",
    "for m, samples in recorded_outputs.items():\n",
    "    for activations in samples:\n",
    "        last_token = activations[-1]\n",
    "        final_tokens[m].append(last_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in final_tokens.keys():\n",
    "    final_tokens[k] = torch.stack(final_tokens[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2560])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tokens[\"model.layers.19.self_attn.v_proj\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_component(data, n_components):\n",
    "    data = data - data.mean(dim=0)\n",
    "    data = data.float()\n",
    "    U, S, V = torch.linalg.svd(data)\n",
    "    steer = V[:,:n_components]\n",
    "    return steer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yy/xq358r8110q5s4y2znmqs1wm0000gn/T/ipykernel_64829/3994786931.py:4: UserWarning: The operator 'aten::linalg_svd' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  U, S, V = torch.linalg.svd(data)\n"
     ]
    }
   ],
   "source": [
    "steer_vectors = {}\n",
    "for m, tokens in final_tokens.items():\n",
    "    steer = principal_component(tokens, 1)\n",
    "    steer_vectors[m] = steer.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.layers.0.self_attn.v_proj': tensor([[-0.0119,  0.0109, -0.0121,  ..., -0.0029, -0.0040,  0.0045]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.1.self_attn.v_proj': tensor([[-0.0213,  0.0288,  0.0082,  ...,  0.0126,  0.0155,  0.0214]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.2.self_attn.v_proj': tensor([[ 0.0116,  0.0221,  0.0303,  ...,  0.0167, -0.0056,  0.0044]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.3.self_attn.v_proj': tensor([[-0.0074,  0.0011,  0.0090,  ..., -0.0228, -0.0062,  0.0028]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.4.self_attn.v_proj': tensor([[-0.0215, -0.0158, -0.0124,  ..., -0.0150, -0.0015,  0.0266]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.5.self_attn.v_proj': tensor([[0.0103, 0.0123, 0.0191,  ..., 0.0062, 0.0069, 0.0089]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.6.self_attn.v_proj': tensor([[ 0.0181, -0.0333, -0.0199,  ...,  0.0403, -0.0140,  0.0475]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.7.self_attn.v_proj': tensor([[ 0.0004,  0.0253, -0.0395,  ...,  0.0220, -0.0023,  0.0107]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.8.self_attn.v_proj': tensor([[-0.0011,  0.0230, -0.0019,  ..., -0.0119,  0.0089, -0.0107]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.9.self_attn.v_proj': tensor([[ 0.0339, -0.0121, -0.0252,  ...,  0.0082,  0.0242, -0.0051]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.10.self_attn.v_proj': tensor([[ 0.0284, -0.0032,  0.0142,  ..., -0.0151,  0.0378, -0.0025]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.11.self_attn.v_proj': tensor([[ 1.4963e-02,  1.3774e-03,  8.8570e-03,  ...,  2.5079e-02,\n",
       "           4.6284e-03, -7.6136e-05]], device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.12.self_attn.v_proj': tensor([[ 0.0025, -0.0133,  0.0573,  ..., -0.0119,  0.0202,  0.0071]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.13.self_attn.v_proj': tensor([[ 0.0010, -0.0137,  0.0222,  ...,  0.0263, -0.0027,  0.0225]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.14.self_attn.v_proj': tensor([[-0.0294, -0.0067,  0.0155,  ..., -0.0229,  0.0212,  0.0132]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.15.self_attn.v_proj': tensor([[-0.0033, -0.0057, -0.0260,  ...,  0.0072, -0.0269,  0.0049]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.16.self_attn.v_proj': tensor([[-0.0161,  0.0216,  0.0251,  ...,  0.0131,  0.0037, -0.0354]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.17.self_attn.v_proj': tensor([[ 0.0305,  0.0059,  0.0171,  ..., -0.0489,  0.0502, -0.0178]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.18.self_attn.v_proj': tensor([[-0.0070,  0.0050,  0.0172,  ..., -0.0250,  0.0142,  0.0237]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.19.self_attn.v_proj': tensor([[-0.0042, -0.0226,  0.0234,  ...,  0.0408,  0.0047,  0.0259]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.20.self_attn.v_proj': tensor([[-0.0164, -0.0026,  0.0114,  ...,  0.0135,  0.0186, -0.0010]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.21.self_attn.v_proj': tensor([[-0.0147,  0.0094,  0.0268,  ...,  0.0077,  0.0037, -0.0057]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.22.self_attn.v_proj': tensor([[-0.0196, -0.0039, -0.0255,  ...,  0.0060, -0.0056,  0.0311]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.23.self_attn.v_proj': tensor([[-0.0185,  0.0184, -0.0143,  ...,  0.0016, -0.0357,  0.0536]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.24.self_attn.v_proj': tensor([[-0.0031, -0.0211, -0.0004,  ...,  0.0282, -0.0150,  0.0092]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.25.self_attn.v_proj': tensor([[ 0.0090, -0.0010,  0.0081,  ..., -0.0130,  0.0083,  0.0192]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.26.self_attn.v_proj': tensor([[-0.0057,  0.0097,  0.0211,  ...,  0.0132,  0.0268, -0.0002]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.27.self_attn.v_proj': tensor([[-0.0043, -0.0215,  0.0120,  ...,  0.0129, -0.0129,  0.0459]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.28.self_attn.v_proj': tensor([[ 0.0522,  0.0078,  0.0075,  ..., -0.0038,  0.0050,  0.0051]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.29.self_attn.v_proj': tensor([[-0.0021,  0.0200,  0.0088,  ...,  0.0142, -0.0117, -0.0065]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.30.self_attn.v_proj': tensor([[-0.0029, -0.0078,  0.0057,  ...,  0.0071,  0.0156,  0.0096]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " 'model.layers.31.self_attn.v_proj': tensor([[-0.0017,  0.0094, -0.0072,  ..., -0.0127,  0.0211, -0.0198]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steer_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteerWrapper(nn.Module):\n",
    "    def __init__(self, layer, steer_vector, steer_magnitude):\n",
    "        super(SteerWrapper, self).__init__()\n",
    "        self.layer = layer\n",
    "        self.steer = steer_vector\n",
    "        self.steer_magnitude = steer_magnitude\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x + self.steer_vector * self.steer_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import replace_submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, vector in steer_vectors.items():\n",
    "    old_module = get_submodule(model, m)\n",
    "    new_module = SteerWrapper(old_module, vector, 0.5)\n",
    "    replace_submodule(model, m, new_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 2560])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(recorded_outputs[\"model.layers.13.self_attn.v_proj\"]).shape\n",
    "# n_tokens, n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_components(data, n_components):\n",
    "    data = data - data.mean(dim=0)\n",
    "    U, S, V = torch.linalg.svd(data)\n",
    "    proj = V[:,:n_components]\n",
    "    return proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
